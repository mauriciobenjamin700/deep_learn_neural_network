{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() #definindo a conversão de imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST(\"./MNIST_data/\", download=True, train=True, transform=transform) #carrega a parte de treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # cria um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST(\"./MNIST_data/\", download=True, train=False, transform=transform) #carrega a parte de validação do dataset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a192e6a450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = dataiter.__next__()\n",
    "plt.imshow(imagens[0].numpy().squeeze(),cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) #para verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) #para verificar as dimensões do tensor de cada etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28,128) #cadama de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128,64) #cadama interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64,10) #camada interna 2, 64 neurônios que se ligam a 10\n",
    "        #para cada camada  de saida não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo,treinloader, device):\n",
    "    \n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #define a política de atualização dos pesos e da bias\n",
    "    inicio = time() #timer para saber quanto tempo levou o treino\n",
    "    \n",
    "    criterio = nn.NLLLoss() #definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10 #numero de epocas que o algoritmo rodará\n",
    "    modelo.train() #ativando o modo de treinamento do modelo\n",
    "    \n",
    "    for epoch in range(0,EPOCHS,1):\n",
    "        perda_acumulada = 0 #inicializando a perda acumulada da epoca em questão\n",
    "        \n",
    "        for imagens, etiquetas in trainloader:\n",
    "            \n",
    "            imagens = imagens.view(imagens.shape[0],-1) #convertendo as imagens para vetores de 28 * 28 casas\n",
    "            otimizador.zero_grad() #zerando os gradientes por conta do ciclo anterior\n",
    "            \n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) #calculando a perda da epoca em questão\n",
    "            \n",
    "            perda_instantanea.backward() #back propagation a partir da perda\n",
    "            \n",
    "            otimizador.step() #atualizando os pesos e a bias\n",
    "            \n",
    "            perda_acumulada += perda_instantanea.item() #atualizando a perda acumulada\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader,device):\n",
    "    conta_corretas, conta_todas = 0,0\n",
    "    for imagens, etiquetas in  valloader:\n",
    "        for i in range(0,len(etiquetas),1):\n",
    "            img = imagens[i].view(1,784)\n",
    "            #desativar autograd para acelerar a validação. Grafos computacionais dinâmicos tem um alto custo de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device))\n",
    "                \n",
    "            ps = torch.exp(logps) # converte output para escala normal (lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) #converte o tensor em número, no caso, o número que o modelo previu\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            \n",
    "            if(etiqueta_certa == etiqueta_pred): #compara da previsão com o valor correto\n",
    "                conta_corretas +=1\n",
    "                \n",
    "            conta_todas +=1\n",
    "                \n",
    "    print(\"todas as imagens testadas = \", conta_todas)\n",
    "    print(\"Precisão do modelo = \",conta_corretas*100/conta_todas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
